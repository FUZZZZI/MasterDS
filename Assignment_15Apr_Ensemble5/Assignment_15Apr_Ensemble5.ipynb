{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a52ba492",
   "metadata": {},
   "source": [
    "### Q1. You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated and there are missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1240a6",
   "metadata": {},
   "source": [
    "### Design a pipeline that includes the following steps\"\n",
    "1. Use an automated feature selection method to identify the important features in the dataset.\n",
    "2. Create a numerical pipeline that includes the following steps.\n",
    "\n",
    "    a. Impute the missing values in the numerical columns using the mean of the column values.\n",
    "    \n",
    "    b. Scale the numerical columns using standardisation.\n",
    "    \n",
    "3. Create a categorical pipeline that includes the following steps.\n",
    "\n",
    "    a. Impute the missing values in the categorical columns using the most frequent value of the column.\n",
    "    \n",
    "    b. One-hot encode the categorical columns.\n",
    "4. Combine the numerical and categorical pipelines using a ColumnTransformer.\n",
    "5. Use a Random Forest Classifier to build the final model.\n",
    "6. Evaluate the accuracy of the model on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c515dbd9",
   "metadata": {},
   "source": [
    "### Note: Your solution should include code snippets for each step of the pipeline, and a brief explanation of each step. You should also provide an interpretation of the results and suggest possible improvements forthe pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26883679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ef4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074b1d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68026570",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "df[\"species\"]=encoder.fit_transform(df[\"species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a893d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "categorical_cols=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e27883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engg Automation\n",
    "num_pipeline=Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"mean\")),     #Handle missing values\n",
    "                             (\"scaler\",StandardScaler())        #Standardization\n",
    "                            ])\n",
    "cat_pipeline=Pipeline(steps=[\"imputer\",SimpleImputer(strategy=\"most_frequent\"),   #Handle missing values\n",
    "                            (\"onehotencoder\", OneHotEncoder())      #Cat features to numerical\n",
    "                            ])\n",
    "preprocessor=ColumnTransformer([(\"num_pipeline\",num_pipeline,numeric_cols),\n",
    "                               (\"cat_pipeline\", cat_pipeline, categorical_cols)\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a074c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of below steps, we can create a final pipline and train, predict, find accuracy on this pipeline\n",
    "\n",
    "# Create the final pipeline\n",
    "\n",
    "#pipeline = Pipeline([\n",
    "#    ('feature_selection', SelectKBest(k=10)), \n",
    "#    ('preprocessor', preprocessor),\n",
    "#    ('classifier', RandomForestClassifier())\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "589a2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent & Dependent features\n",
    "X=df.drop(\"species\", axis=1)\n",
    "y=df[\"species\"]\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cae93482",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=preprocessor.fit_transform(X_train)\n",
    "X_test=preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8af1f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': 1.0, 'Decision Tree': 1.0, 'SVM': 1.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automate Model train process\n",
    "models={\n",
    "    \"Random Forest\":RandomForestClassifier(),\n",
    "    \"Decision Tree\":DecisionTreeClassifier(),\n",
    "    \"SVM\":SVC()\n",
    "}\n",
    "\n",
    "def evaluate_model(X_train,y_train,X_test,y_test,models):\n",
    "    report={}\n",
    "    for i in range(len(models)):\n",
    "        model=list(models.values())[i]\n",
    "        \n",
    "        #Train model\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        #Predict test data\n",
    "        y_test_pred=model.predict(X_test)\n",
    "        \n",
    "        #Get accuracy\n",
    "        test_model_score=accuracy_score(y_test,y_test_pred)\n",
    "        \n",
    "        report[list(models.keys())[i]] = test_model_score\n",
    "        \n",
    "    return report\n",
    "        \n",
    "evaluate_model(X_train,y_train,X_test,y_test,models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f9a8dd",
   "metadata": {},
   "source": [
    "All the 3 classifiers give an accuracy of 100%. This is due to non-complexity nature of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3fd9d5",
   "metadata": {},
   "source": [
    "### Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "345eaa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Load voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Create the Logistic Regression Classifier\n",
    "lr_classifier = LogisticRegression()\n",
    "\n",
    "# Create the Voting Classifier\n",
    "voting_classifier=VotingClassifier(estimators=[(\"rf\",rf_classifier),(\"lr\",lr_classifier)],voting=\"hard\")\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the model on the test data\n",
    "y_pred = voting_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efc96c6",
   "metadata": {},
   "source": [
    "Here also, we will get the accuracy of 100% as individual models are also giving the same accuracy due to the same reson."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
